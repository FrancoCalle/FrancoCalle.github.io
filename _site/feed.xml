<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-11-08T12:52:35-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Franco Calle</title><subtitle></subtitle><author><name>Franco Calle</name></author><entry><title type="html">Discrete Choice Models - Matlab</title><link href="http://localhost:4000/dcm/" rel="alternate" type="text/html" title="Discrete Choice Models - Matlab" /><published>2018-01-28T00:00:00-05:00</published><updated>2018-01-28T00:00:00-05:00</updated><id>http://localhost:4000/dcm</id><content type="html" xml:base="http://localhost:4000/dcm/">&lt;h2 id=&quot;package-for-estimation-and-simulation-of-discrete-choice-models-matlab&quot;&gt;Package for estimation and simulation of discrete choice models [Matlab]&lt;/h2&gt;

&lt;p&gt;Discrete choice models are becoming trendier as the availability of data increases in multiple areas like health, education, credit markets, and many others. The key idea of them is to model the decision making of an individual to choose a particular option among a discrete set of them, based on individual and option level characteristics. An application of this method could be to estimate the probability of a family choosing where to enroll their kids from an array of schools available near their neighborhood, or estimate the probability of choosing a particular mean of transportation for an individual to get to work.&lt;/p&gt;

&lt;!-- *italics* --&gt;

&lt;p&gt;I developed a package in Matlab, (Python and Julia versions forthcoming) that estimates different static versions of discrete choice models that maximize the likelihood or the joint likelihood of different decision problems. In this blog post I pretend to explain the code and how it works but not the mathematical details of it, for this I recommend reading  Discrete choice methods with simulation by Kenneth Train 2009.&lt;/p&gt;

&lt;p&gt;The whole package for my code can be found &lt;a href=&quot;https://github.com/FrancoCalle/DiscreteChoiceModels/tree/master/matlab&quot;&gt;here&lt;/a&gt;
The most simple way of testing it is to clone the repository, open matlab and run mainLogit. I know that Matlab is an object oriented language and defining all the functions within a single class can be very computationally inefficient, however, I decided to have all the code in one class anyways to prevent the repo to be overload with many .m files. If you’re looking for more efficiency, I recommend separating the functions in different .m files, I did that for other project and it worked 100% guaranteed.&lt;/p&gt;

&lt;p&gt;Ok, here we go!&lt;/p&gt;

&lt;!-- Python code block:
```python
    import numpy as np

    def test_function(x, y):
      z = np.sum(x,y)
      return z
``` --&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Data.XX = {};
for ii = 1:nXX
    Data.XX{ii} = randn(nStudents,nOptions); %Variable 1
end
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Pack.Model = 'Model 1'; %This define the type of model to estimate

parameters = dcmLab.setupParameters();
% 1.5. Generate Choices
dcmLab.generateFakeChoices(parameters, false); %Estimate fake data
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;passedUtilityFunction = @(parameters) dcmLab.utilityFunction(parameters,  true);
dcmLab.checkGradient(parameters,passedUtilityFunction)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;passedUtilityFunction = @(theta) dcmLab.utilityFunction(theta, true);
[theta_quasinewton,fobj1,~,~]=dcmLab.estimationNLP(theta_init, passedUtilityFunction);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%4.1. Define batch size:
batchSize = 2^10;
nIter = 120;
%4.2. What happens when we start from the true values?
initial_values  = theta_init(1,:); %initial_values  = theta_init(s,:);

passedUtilityFunction = @(theta) dcmLab.utilityFunction(theta, true);
[theta_estimated_Adam, allTheta]= dcmLab.optimizationAlgorithm(initial_values, batchSize, 'Adam', nIter, passedUtilityFunction);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here’s some inline code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x+y&lt;/code&gt;.&lt;/p&gt;

&lt;!-- Here's an image:
&lt;img src=&quot;http://localhost:4000/images/dcm/parameters_convergence_no_rc.jpg&quot; alt=&quot;linearly separable data&quot;&gt; --&gt;

&lt;p&gt;How parameters converge after 120 iterations using stochastic gradient descent:
&lt;img src=&quot;http://localhost:4000/images/dcm/parameters_convergence_no_rc.jpg&quot; alt=&quot;alt&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here are some simulations of option removal. Evidently, less options imply less utility.
&lt;img src=&quot;http://localhost:4000/images/dcm/policy_change.jpg&quot; alt=&quot;alt&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here’s some math:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z=x+y&lt;/script&gt;

&lt;p&gt;You can also put it inline &lt;script type=&quot;math/tex&quot;&gt;z=x+y&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Bibliography:&lt;/p&gt;

&lt;p&gt;Train, K., &amp;amp; Weeks, M. (2005). Discrete choice models in preference space and willingness-to-pay space. In Applications of simulation methods in environmental and resource economics (pp. 1-16). Springer, Dordrecht.&lt;/p&gt;</content><author><name>Franco Calle</name></author><category term="logit" /><category term="discrete choice model" /><category term="behavioral model" /><summary type="html">Behavioral Modelling - Python &amp; Matlab</summary></entry></feed>